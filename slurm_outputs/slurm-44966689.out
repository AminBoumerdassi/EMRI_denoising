
The following modules were not unloaded:
   (Use "module --force purge" to unload all):

  1) XALT/minimal   2) slurm   3) NeSI
2024-03-25 16:46:44.455243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-03-25 16:46:44.455318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-03-25 16:46:44.455349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-03-25 16:46:44.464949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-25 16:46:47.853439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38298 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:05:00.0, compute capability: 8.0
1 Physical GPUs, 1 Logical GPUs
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv1d (Conv1D)             (None, 1048576, 32)       8224      
                                                                 
 conv1d_1 (Conv1D)           (None, 262144, 16)        65552     
                                                                 
 conv1d_2 (Conv1D)           (None, 65536, 8)          16392     
                                                                 
 conv1d_transpose (Conv1DTr  (None, 262144, 8)         8200      
 anspose)                                                        
                                                                 
 conv1d_transpose_1 (Conv1D  (None, 1048576, 16)       16400     
 Transpose)                                                      
                                                                 
 conv1d_transpose_2 (Conv1D  (None, 4194304, 32)       65568     
 Transpose)                                                      
                                                                 
 conv1d_transpose_3 (Conv1D  (None, 4194304, 2)        66        
 Transpose)                                                      
                                                                 
 activation (Activation)     (None, 4194304, 2)        0         
                                                                 
=================================================================
Total params: 180402 (704.70 KB)
Trainable params: 180402 (704.70 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
#################################
####DATA GENERATOR PARAMETERS####
#Batch size:  8
#Time in years: 1.3290715810104465
#n_channels:  2
#dt:  10
#Length of timeseries: 4194304
Noise background:  True
#################################
Epoch 1/40
2024-03-25 16:47:07.239269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600
2024-03-25 16:49:51.466905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ab279fb4780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-03-25 16:49:51.467786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2024-03-25 16:49:51.484463: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-03-25 16:49:51.803280: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/1 [==============================] - ETA: 0s - loss: 0.92171/1 [==============================] - 1s 580ms/step - loss: 0.9217
Noise loss:  0.9217032194137573
10/10 - 216s - loss: 2.3052e-04 - val_loss: 2.1508e-05 - 216s/epoch - 22s/step
Epoch 2/40
1/1 [==============================] - ETA: 0s - loss: 0.92241/1 [==============================] - 0s 393ms/step - loss: 0.9224
Noise loss:  0.9223592877388
10/10 - 48s - loss: 1.4886e-05 - val_loss: 9.1891e-06 - 48s/epoch - 5s/step
Epoch 3/40
1/1 [==============================] - ETA: 0s - loss: 0.92181/1 [==============================] - 0s 405ms/step - loss: 0.9218
Noise loss:  0.9218196272850037
10/10 - 48s - loss: 5.9605e-06 - val_loss: 3.5116e-06 - 48s/epoch - 5s/step
Epoch 4/40
1/1 [==============================] - ETA: 0s - loss: 0.92161/1 [==============================] - 0s 397ms/step - loss: 0.9216
Noise loss:  0.9215781092643738
10/10 - 48s - loss: 2.4268e-06 - val_loss: 1.5347e-06 - 48s/epoch - 5s/step
Epoch 5/40
1/1 [==============================] - ETA: 0s - loss: 0.92171/1 [==============================] - 0s 434ms/step - loss: 0.9217
Noise loss:  0.9217303991317749
10/10 - 48s - loss: 1.1933e-06 - val_loss: 8.5669e-07 - 48s/epoch - 5s/step
Epoch 6/40
1/1 [==============================] - ETA: 0s - loss: 0.92151/1 [==============================] - 0s 432ms/step - loss: 0.9215
Noise loss:  0.9215465188026428
10/10 - 50s - loss: 7.0841e-07 - val_loss: 5.6243e-07 - 50s/epoch - 5s/step
Epoch 7/40
1/1 [==============================] - ETA: 0s - loss: 0.92241/1 [==============================] - 0s 413ms/step - loss: 0.9224
Noise loss:  0.9223669767379761
10/10 - 50s - loss: 4.7902e-07 - val_loss: 3.9997e-07 - 50s/epoch - 5s/step
Epoch 8/40
1/1 [==============================] - ETA: 0s - loss: 0.92181/1 [==============================] - 0s 418ms/step - loss: 0.9218
Noise loss:  0.9217607975006104
10/10 - 48s - loss: 3.5682e-07 - val_loss: 3.1038e-07 - 48s/epoch - 5s/step
Epoch 9/40
1/1 [==============================] - ETA: 0s - loss: 0.92181/1 [==============================] - 0s 410ms/step - loss: 0.9218
Noise loss:  0.9217552542686462
10/10 - 48s - loss: 2.8288e-07 - val_loss: 2.5301e-07 - 48s/epoch - 5s/step
Epoch 10/40
1/1 [==============================] - ETA: 0s - loss: 0.92191/1 [==============================] - 0s 378ms/step - loss: 0.9219
Noise loss:  0.9218842387199402
10/10 - 48s - loss: 2.3322e-07 - val_loss: 2.1172e-07 - 48s/epoch - 5s/step
Epoch 11/40
1/1 [==============================] - ETA: 0s - loss: 0.92191/1 [==============================] - 0s 410ms/step - loss: 0.9219
Noise loss:  0.9219496846199036
10/10 - 48s - loss: 1.9718e-07 - val_loss: 1.8084e-07 - 48s/epoch - 5s/step
Epoch 12/40
1/1 [==============================] - ETA: 0s - loss: 0.92191/1 [==============================] - 0s 410ms/step - loss: 0.9219
Noise loss:  0.9219310879707336
10/10 - 49s - loss: 1.6956e-07 - val_loss: 1.5674e-07 - 49s/epoch - 5s/step
Epoch 13/40
1/1 [==============================] - ETA: 0s - loss: 0.92191/1 [==============================] - 0s 411ms/step - loss: 0.9219
Noise loss:  0.9219183921813965
10/10 - 49s - loss: 1.4768e-07 - val_loss: 1.3728e-07 - 49s/epoch - 5s/step
Epoch 14/40
1/1 [==============================] - ETA: 0s - loss: 0.92171/1 [==============================] - 0s 420ms/step - loss: 0.9217
Noise loss:  0.9217082262039185
10/10 - 49s - loss: 1.2984e-07 - val_loss: 1.2131e-07 - 49s/epoch - 5s/step
Epoch 15/40
1/1 [==============================] - ETA: 0s - loss: 0.92201/1 [==============================] - 0s 413ms/step - loss: 0.9220
Noise loss:  0.9220134615898132
10/10 - 49s - loss: 1.1504e-07 - val_loss: 1.0786e-07 - 49s/epoch - 5s/step
Epoch 16/40
1/1 [==============================] - ETA: 0s - loss: 0.92211/1 [==============================] - 0s 401ms/step - loss: 0.9221
Noise loss:  0.9221410155296326
10/10 - 48s - loss: 1.0264e-07 - val_loss: 9.6588e-08 - 48s/epoch - 5s/step
Epoch 17/40
1/1 [==============================] - ETA: 0s - loss: 0.92191/1 [==============================] - 0s 450ms/step - loss: 0.9219
Noise loss:  0.9218779802322388
10/10 - 48s - loss: 9.2076e-08 - val_loss: 8.6894e-08 - 48s/epoch - 5s/step
Epoch 18/40
1/1 [==============================] - ETA: 0s - loss: 0.92171/1 [==============================] - 0s 405ms/step - loss: 0.9217
Noise loss:  0.9217491745948792
10/10 - 49s - loss: 8.3055e-08 - val_loss: 7.8579e-08 - 49s/epoch - 5s/step
Epoch 19/40
1/1 [==============================] - ETA: 0s - loss: 0.92171/1 [==============================] - 0s 381ms/step - loss: 0.9217
Noise loss:  0.9217430353164673
10/10 - 49s - loss: 7.5220e-08 - val_loss: 7.1322e-08 - 49s/epoch - 5s/step
Epoch 20/40
slurmstepd: error: *** JOB 44966689 ON wbl004 CANCELLED AT 2024-03-25T04:11:28 ***
